<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Infrastructure | euccas.github.io]]></title>
  <link href="http://euccas.github.io/categories/infrastructure/atom.xml" rel="self"/>
  <link href="http://euccas.github.io/"/>
  <updated>2017-04-23T20:13:37+08:00</updated>
  <id>http://euccas.github.io/</id>
  <author>
    <name><![CDATA[euccas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A List of SoC Design and Verification Infrastructure Needs - Tools/Automation Flows (2013)]]></title>
    <link href="http://euccas.github.io/20170213/a-list-of-soc-design-and-verification-infrastructure-needs.html"/>
    <updated>2017-02-13T07:53:19+08:00</updated>
    <id>http://euccas.github.io/20170213/a-list-of-soc-design-and-verification-infrastructure-needs</id>
    <content type="html"><![CDATA[<p><em>This post was written in 2013, when I thought it was necessary to summarize infrastructure tools and flows needed in SoC design and verification, according to all my experience. Today when I checked on my old notes I found this one and would like to share it here. Later on I’ll update and expand this list according to my latest experience and knowledge in engineering tools and infrastructure for software and hardware development.</em></p>

<p>System-on-Chip design and verification process is a complicated one. Unlike the world of Web and Internet, the design and development of hardware products have higher risk and lower tolerance to any mistakes. SoC design and verification process requires collaborations from multiple teams and vendors. Lots of hard decisions to make. Lots of trade-offs to consider. Moreover, the nonrecurring-engineering (NRE) charge makes sufficient and solid verification a must with limited time and resource. Tools and automated flows are an essential part of any design house.</p>

<p>Here is a list of areas that need tools and flows for SoC software and hardware design and verification according to my experience.</p>

<!--more-->

<table>
<tr>
	<th>Usage Area of Tools/Flows</th>
	<th>Software</th>
	<th>Hardware</th>
	<th>Design Usage</th>
	<th>Verification Usage</th>
</tr>

<tr>
	<td>Test Generation</td>
	<td>x</td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Regression System</td>
	<td>x</td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Coverage Reporting</td>
	<td>x</td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Coding Style Check</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Code Review System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Code Quality Analysis</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Build System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

<tr>
	<td>Version Control</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

<tr>
	<td>Integration System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Spec System</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>RTL Generation</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>TestBench Generation</td>
	<td></td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Synthesis</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Netlist Quality Analysis</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Power Analysis and Optimization</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>ECO Flow</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Issue/Bug Tracking System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

<tr>
	<td>Infrastructure: Linux/Windows machines, LSF</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GTAC: The Uber Challenge of Cross-Application Testing]]></title>
    <link href="http://euccas.github.io/20160929/the-uber-challenge-of-cross-application-testinng.html"/>
    <updated>2016-09-29T14:17:30+08:00</updated>
    <id>http://euccas.github.io/20160929/the-uber-challenge-of-cross-application-testinng</id>
    <content type="html"><![CDATA[<p>Inspired by Matt Cutts’ TED talk: <a href="https://www.ted.com/talks/matt_cutts_try_something_new_for_30_days?language=en">Try something new for 30 days</a>, I’m starting a “30 Days of GTAC” project. Google’s Test Automation Conference <a href="https://developers.google.com/google-test-automation-conference/">GTAC</a> is an annual test automation conference which brings together engineers from industry and academia to discuss advances in test automation and related engineering tools. In my “30 Days of GTAC” project, I’ll review the topics presented on GTAC. My goal is having a better and deeper understanding in modern testing technologies, methodologies, strategies, and practices.</p>

<p>Get it started! Day#1 topic is:</p>

<p><strong>The Uber Challenge of Cross-Application/Cross-Device Testing</strong></p>

<!--more-->

<ul>
  <li>Presenter: Apple Chow (Uber), Bian Jiang (Uber)</li>
  <li><a href="https://www.youtube.com/watch?v=p6gsssppeT0&amp;list=PLSIUOFhnxEiCWGsN9t5A-XOhRbmz54IS1&amp;index=3">Video</a></li>
  <li><a href="https://docs.google.com/presentation/d/1vYXhkvgLKun72Ix91LQDDWZQdcY5VOBqKVvI1Y6riYo/pub">Slides</a></li>
</ul>

<p><strong>My takeaways</strong></p>

<ul>
  <li>The challenge: End-to-end tests require cross application communication (between rider app and driver app)</li>
  <li>Uber’s solution: Octopus
    <ul>
      <li>Octopus coordinates communication across different apps running on different devices</li>
      <li>This solution can be adopted for any tests that require coordination/communication across different apps or devices</li>
    </ul>
  </li>
  <li>What makes testing Uber’s mobile apps significantly different from testing Google Maps?</li>
  <li>Why (built) Octopus? Unified (iOS and Android). Extensible (Integrate with different UI testing frameworks). Parallelized. Signaling (enabling cross-app and cross-device testing).</li>
  <li>What does Octopus do? Prepare test targets. Run tests (handles signaling). Create test results reports. Pull test artifacts. Perform clean ups. All from simple command line.</li>
  <li>Signaling between driver test and rider test: Conducted with Test Host to improve the consistency. API readSignal (blocking), writeSignal (nonblocking). Test hosts and test targets are connected via USB (reliable).</li>
  <li>Apple Chow wrote about Octopus on <a href="http://eng.uber.com/rescued-by-octopus/">Uber Engineering</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
