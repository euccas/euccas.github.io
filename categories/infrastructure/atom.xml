<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Infrastructure | euccas.github.io]]></title>
  <link href="http://euccas.github.io/categories/infrastructure/atom.xml" rel="self"/>
  <link href="http://euccas.github.io/"/>
  <updated>2017-11-29T00:33:45-08:00</updated>
  <id>http://euccas.github.io/</id>
  <author>
    <name><![CDATA[euccas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Facebook Infrastructure: Streaming Video Engine (SVE)]]></title>
    <link href="http://euccas.github.io/blog/20170627/facebook-infrastructure-streaming-video-engine-sve.html"/>
    <updated>2017-06-27T22:16:02-07:00</updated>
    <id>http://euccas.github.io/blog/20170627/facebook-infrastructure-streaming-video-engine-sve</id>
    <content type="html"><![CDATA[<p>In last year’s <a href="https://developers.facebook.com/videos/?category=f8_2016"><strong>Facebook F8 conference</strong></a>, Sachin Kulkarni, who worked on Facebook’s Video Infrastructure, gave a talk (<a href="https://developers.facebook.com/videos/f8-2016/inside-look-at-facebook-media-infrastructure/">watch it here</a>) to introduce the design of Facebook’s <strong>Streaming Video Engine System (SVE)</strong>. I found this talk particularly interesting because it revealed, in a very well structured, concise yet informative way, how Facebook infrastructure team came up with a solution to build a video system solving user frustrations by reviewing the end-to-end process, and how such a design meet the goal of being <strong>fast</strong>, <strong>flexible</strong>, <strong>scalable</strong>, and <strong>efficient</strong>. After watching the presentation video for a few times, I thought it would be helpful to write down some notes here, for my own reviewing in the future, and for people who might be interested in Facebook’s media infrastructure.</p>

<p>Sharing on Facebook started from largely text, and quickly changed to be largely photos. Since 2014, more videos started to be posted and shared among users. The challenge was, building a video processing system is much harder than building a text or image processing system. Videos are greedy, they will consume all your resources: CPU, memory, disk, network, and anything else.</p>

<p>Before building the Streaming Video Engine system, the team started by reviewing Facebook’s existing video uploading and processing process, which was slow and not scalable. They found several problems need change or improvement:</p>

<ul>
  <li>No unified clients</li>
  <li>Several disk reads and writes in the critical path</li>
  <li>Was doing serial processing throughout</li>
  <li>Read a video as one single big file, instead of splitting it up to chunks</li>
</ul>

<p>The new Streaming Video Engine (SVE) is expected to solve the aforementioned problems, and to meet the four design goals:</p>

<ul>
  <li>Fast: make users upload their videos super fast</li>
  <li>Flexible: usable for different Facebook products</li>
  <li>Scalable: everything at Facebook has to scale</li>
  <li>Efficient: storage efficiency, processing efficiency, and more importantly consume less bytes of users’ data plan</li>
</ul>

<!--more-->

<p>These four design goals, in my opinion, are also the most common goals applicable to most engineering infrastructure systems.</p>

<p>Let’s take a deep dive to see how SVE was designed to meet these goals.</p>

<h1 id="fast">Fast</h1>

<ul>
  <li>First step is build a common library (for video uploading) that could be used for the clients cross platforms (Web, Mobile, Android, etc.). With the common library, optimizations on video uploading can be applied to all platforms.</li>
  <li>The uploading library has functions to split a video by GOP (Group of Pictures, a GOP roughly is a scene in the video) alignment. So any given video can be split to segments, which can have multiple GOPs.</li>
  <li>Uploading process starts as soon as the clients split a video into segaments. The <strong>client</strong> uploads one segment a time to the <strong>web server</strong>.</li>
  <li>Web server sends out segments to the <strong>preprocessor</strong>, which is a write-through cache.</li>
  <li>Proprocessor handles:
    <ul>
      <li>Normalize the video (segment) if it needs to</li>
      <li>Notify the <strong>scheduler</strong> that there are video segments available to be encoded</li>
      <li>Write the video (segment) to the <strong>original storage</strong></li>
      <li>Further split the video segment into GOPs</li>
    </ul>
  </li>
  <li>Scheduler will find workers to encode videos. Multiple works can be utilized and each worker will process one or multiple GOPs.</li>
  <li>Overlapped upload and encoding process: While proprocessor, scheduler and works are working, the uploading process is still ongoing. Clients continues splitting videos into segments and uploading to the web server.</li>
</ul>

<p>{% img center /images/post_images/2017/20170627-fb_00.png 600px %}</p>

<p>With this design, the process speedup reached 2.3x (small videos &lt; 3MB) ~ 9.3x (large videos &gt; 1G).</p>

<h1 id="flexible">Flexible</h1>

<ul>
  <li>The key insight that allows SVE to be flexible is, all the video processing pipelines can be represented as a DAG (Directed Acyclic Graph).</li>
  <li>Arbitrary dependencies can be added between the tasks in the video processing pipepline. The added tasks can be executed in parallel while the main pipeline tasks are running.</li>
  <li>SVE provides very simple API functions for the video pipeline (Ideally, you can add a video processing pipeline in your product in less than 10 lines of code).</li>
</ul>

<p>{% img center /images/post_images/2017/20170627-fb_01.png 600px %}</p>

<h1 id="scalable">Scalable</h1>

<ul>
  <li>SVE was designed to prepare for overloads, such as handling the worldwide uploading “spike” on New Year’s Eve (could be 3x video uploads).</li>
  <li>Building a scalable system is relevant only when the system is <strong>robust</strong>. When the system gets overloaded, it must <strong>gracefully degrade</strong>. It cannot crash and burn.</li>
  <li>Prepare for overload along two dimensions: at the pipeline level, and the task level.</li>
  <li>Pipeline level, when uploads overwhelm the system:
    <ul>
      <li>Do not cache original videos in upload: Preprocessor stops caching original videos. Workers then need fetch videos from the original storage, not from preprocessor. The cost here is disk latency is added to the critical path.</li>
      <li>Delay pipeline generation for incoming video. Distinguish the critical video pipeline requests and the non-critical ones, then delay the non-critical ones.</li>
      <li>Reroute traffic to a different (less busy) region (Asia, Europe, US west, etc.)</li>
    </ul>
  </li>
  <li>Task level (the tasks executed by <strong>workers</strong> in the pipeline), when too many tasks are running:
    <ul>
      <li>Push back non latency-sensitive jobs</li>
      <li>Turn off A/B tests, which try to figure out the best encoding for the given video</li>
      <li>Add more workers (this requires making it easy to add capacity to SVE)</li>
    </ul>
  </li>
</ul>

<h1 id="efficient">Efficient</h1>

<ul>
  <li>The high level problem statement here is: If we could use 100% CPU, how can we make the encoded video as small as possible?</li>
  <li>Find the optimal encoding settings to get the best balance between encoded video file size and time spent on encoding. The difficult part is modern encoders can have hundreds of settings for one video. Chance of picking optimal combination is extremely low.</li>
  <li>The adopted solution is:
    <ul>
      <li>Categorize each scene such as “minimal motion”, “rapid movement”, and “complex crowded scene”.</li>
      <li>Build a Neural Network Model and a large training data set to train the network.</li>
      <li>In SVE, video scene segments are sent to a Fingerprint generator, which generates fingerprints and sends them to the Neural Network Model.</li>
      <li>The neural network figures out optimal encoding settings (could be multiple) for each scene, and sends the encoding settings to encoders.</li>
      <li>the encoder takes the settings, and encodes the video scenes in multiple ways. Then discard the encoded videos which are below quality bar.</li>
    </ul>
  </li>
</ul>

<p>{% img center /images/post_images/2017/20170627-fb_02.png 600px %}</p>

<p>SVE achieved 20% smaller video file sizes. This is a huge saving of user’s data plans.</p>

<p>This Streaming Video Engine was designed, coded and tested in roughly 9 months. The most important learnings are:</p>

<ul>
  <li>E2E view: To find an optimal solution, we need look at the flow end to end</li>
  <li>Multi-dimensional flexibility is a key for making the system most useful</li>
  <li>Parallel and shadow mode testing to find correctness and scalability issues before production</li>
  <li>Design the ability to handle extreme products such as 360 videos</li>
  <li>Track direct measures (latency, reliability, etc.) and indirect measures (number of videos uploaded, watch times, etc.). Mapping indirect measures to direct measures could give you a good view in figuring out what you could do better next.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How Instagram Moved to Python 3]]></title>
    <link href="http://euccas.github.io/blog/20170616/how-instagram-moved-to-python-3.html"/>
    <updated>2017-06-16T17:52:34-07:00</updated>
    <id>http://euccas.github.io/blog/20170616/how-instagram-moved-to-python-3</id>
    <content type="html"><![CDATA[<p>Instagram, the famous brunch sharing app, presented in <a href="https://us.pycon.org/2017/">PyCon 2017</a> and gave a talk in the keynote session on “How Instagram moves to Python 3”. If you have 15 minutes, read the interview with the speakers, Hui Ding and Lisa Guo from Instagram Infrastructure team, <a href="https://thenewstack.io/instagram-makes-smooth-move-python-3/]"><strong>here</strong></a>. If you have 45 minutes, watch their PyCon talk video, <a href="https://www.youtube.com/watch?v=66XoCk79kjM"><strong>here</strong></a>. If you have only 5 minutes, continue reading, <strong>right here</strong>.</p>

<p>Instagram’s backend, which serves over 400 million active users every day, is built on Python/Django stack. The decision on whether moving from Python 2 to Python 3, was really a decision on whether investing in a version of the language that was mature, but wasn’t going anywhere (Python 2 is expected to retire in 2020) – or the language that was the next version and had great and growing community support. The major motivations behind Instagram’s migration to Python 3 are:</p>

<ul>
  <li><strong>Typing support</strong> for dev velocity</li>
  <li>Better <strong>performance</strong> than Python 2</li>
  <li><strong>Community</strong> continues to make Python 3 better and faster</li>
</ul>

<p>The whole migration process took about 10 months, in roughly 3 stages.</p>

<!--more-->

<p>{% img center /images/post_images/2017/20170616-instagram_python3_00.png 520px %}</p>

<ul>
  <li>First off, the migration was done directly on the Master Branch, which means the developers were adding new features to the code while migration was ongoing. So in the beginning of the Mirgration process, infrastructure added support of Python 3 on the Master Branch to make the code be able to run with both Python 2 and Python 3 environment.</li>
  <li>Massive code modification for 3 months, with the help of Python package <a href="https://pypi.python.org/pypi/modernize"><strong>“modernize”</strong></a>. Meanwhile, upgraded Third-party packages to Python 3 (working rule: <em>No Python 3, no new package</em>). Also deleted unused, incompatible packages.</li>
  <li>Intensive unit testing for 2 months. One limitation is data compatibility issues typically do not show up in unit tests.</li>
  <li>Production rollout for another 4 months (push Python 3 to every developer’s sandbox)</li>
</ul>

<p>In the talk, Lisa shared the challenges they faced in the migration process and how did they solved those problems.</p>

<ul>
  <li>Differences in <strong>unicode</strong>, <strong>str</strong>, <strong>bytes</strong>. Solved by using helper functions.</li>
  <li><strong>Pickle memcache data format incompatibility</strong> in Python 2 and Python 3. Solved by isolating memcaches for Python 2 and Python 3.</li>
  <li><strong>Iterator</strong> differences, such as <code>map</code>. Solved by converting all maps to list in Python 3.</li>
  <li><strong>Dictionary order</strong> is different in different Python versions, which caused differences in the dumped JSON data. Solved by forcing <code>sorted_keys</code> in <code>json.dump</code> function.</li>
  <li>With Python 3, while CPU instructions per request decreased by 12%, max requests per second (capacity) had 0% increase! Found the root cause in the code of checking memory configuration, and the issue was memory optimization condition was never met in Python 3 as <code>True</code> because of unicode issue. Solved by adding a magical character <strong>“b”</strong>, just like this:</li>
</ul>

<p>{% img center /images/post_images/2017/20170616-instagram_python3_01.png 520px %}</p>

<p>In Feb 2017, Instagram’s stack completely dropped Python 2 and moved to Python 3 (v3.6). So far they’ve got this from Python 3:</p>

<p>{% img center /images/post_images/2017/20170616-instagram_python3_02.png 520px %}</p>

<p>One more thing, in the talk Hui Ding also briefly discussed a few <strong>Python Efficiency Strategies</strong> that Instagram used to support the growing number of features and users:</p>

<ul>
  <li>Build extensive tools to profile and understand perf bottleneck</li>
  <li>Proactively push stable, critical components to C/C++, e.g., memcached access library</li>
  <li>Use Cythonization to improve performance</li>
  <li>Future ideas: Make the Django stack completely Async? Create a new python runtime?</li>
</ul>

<p>Changing an existing service to use a new version of language can never be easy, especially when your service is at such a scale - serving millions of people. You just cannot afford to breaking the existing service. Moving to Python 3 in 10 months must be a challenging process. “It can be done. It worths it. Make it happen. And Make Python 3 better.”</p>

<p>Nice work Instagram!</p>

<p>{% img center /images/post_images/2017/20170616-instagram_python3_03.png 520px %}</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A List of SoC Design and Verification Infrastructure Needs - Tools/Automation Flows (2013)]]></title>
    <link href="http://euccas.github.io/blog/20170212/a-list-of-soc-design-and-verification-infrastructure-needs.html"/>
    <updated>2017-02-12T15:53:19-08:00</updated>
    <id>http://euccas.github.io/blog/20170212/a-list-of-soc-design-and-verification-infrastructure-needs</id>
    <content type="html"><![CDATA[<p><em>This post was written in 2013, when I thought it was necessary to summarize infrastructure tools and flows needed in SoC design and verification, according to all my experience. Today when I checked on my old notes I found this one and would like to share it here. Later on I’ll update and expand this list according to my latest experience and knowledge in engineering tools and infrastructure for software and hardware development.</em></p>

<p>System-on-Chip design and verification process is a complicated one. Unlike the world of Web and Internet, the design and development of hardware products have higher risk and lower tolerance to any mistakes. SoC design and verification process requires collaborations from multiple teams and vendors. Lots of hard decisions to make. Lots of trade-offs to consider. Moreover, the nonrecurring-engineering (NRE) charge makes sufficient and solid verification a must with limited time and resource. Tools and automated flows are an essential part of any design house.</p>

<p>Here is a list of areas that need tools and flows for SoC software and hardware design and verification according to my experience.</p>

<!--more-->

<table>
<tr>
	<th>Usage Area of Tools/Flows</th>
	<th>Software</th>
	<th>Hardware</th>
	<th>Design Usage</th>
	<th>Verification Usage</th>
</tr>

<tr>
	<td>Test Generation</td>
	<td>x</td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Regression System</td>
	<td>x</td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Coverage Reporting</td>
	<td>x</td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Coding Style Check</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Code Review System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Code Quality Analysis</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Build System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

<tr>
	<td>Version Control</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

<tr>
	<td>Integration System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Spec System</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>RTL Generation</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>TestBench Generation</td>
	<td></td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Synthesis</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Netlist Quality Analysis</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Power Analysis and Optimization</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>ECO Flow</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Issue/Bug Tracking System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

<tr>
	<td>Infrastructure: Linux/Windows machines, LSF</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GTAC: The Uber Challenge of Cross-Application Testing]]></title>
    <link href="http://euccas.github.io/blog/20160928/the-uber-challenge-of-cross-application-testinng.html"/>
    <updated>2016-09-28T23:17:30-07:00</updated>
    <id>http://euccas.github.io/blog/20160928/the-uber-challenge-of-cross-application-testinng</id>
    <content type="html"><![CDATA[<p>Inspired by Matt Cutts’ TED talk: <a href="https://www.ted.com/talks/matt_cutts_try_something_new_for_30_days?language=en">Try something new for 30 days</a>, I’m starting a “30 Days of GTAC” project. Google’s Test Automation Conference <a href="https://developers.google.com/google-test-automation-conference/">GTAC</a> is an annual test automation conference which brings together engineers from industry and academia to discuss advances in test automation and related engineering tools. In my “30 Days of GTAC” project, I’ll review the topics presented on GTAC. My goal is having a better and deeper understanding in modern testing technologies, methodologies, strategies, and practices.</p>

<p>Get it started! Day#1 topic is:</p>

<p><strong>The Uber Challenge of Cross-Application/Cross-Device Testing</strong></p>

<!--more-->

<ul>
  <li>Presenter: Apple Chow (Uber), Bian Jiang (Uber)</li>
  <li><a href="https://www.youtube.com/watch?v=p6gsssppeT0&amp;list=PLSIUOFhnxEiCWGsN9t5A-XOhRbmz54IS1&amp;index=3">Video</a></li>
  <li><a href="https://docs.google.com/presentation/d/1vYXhkvgLKun72Ix91LQDDWZQdcY5VOBqKVvI1Y6riYo/pub">Slides</a></li>
</ul>

<p><strong>My takeaways</strong></p>

<ul>
  <li>The challenge: End-to-end tests require cross application communication (between rider app and driver app)</li>
  <li>Uber’s solution: Octopus
    <ul>
      <li>Octopus coordinates communication across different apps running on different devices</li>
      <li>This solution can be adopted for any tests that require coordination/communication across different apps or devices</li>
    </ul>
  </li>
  <li>What makes testing Uber’s mobile apps significantly different from testing Google Maps?</li>
  <li>Why (built) Octopus? Unified (iOS and Android). Extensible (Integrate with different UI testing frameworks). Parallelized. Signaling (enabling cross-app and cross-device testing).</li>
  <li>What does Octopus do? Prepare test targets. Run tests (handles signaling). Create test results reports. Pull test artifacts. Perform clean ups. All from simple command line.</li>
  <li>Signaling between driver test and rider test: Conducted with Test Host to improve the consistency. API readSignal (blocking), writeSignal (nonblocking). Test hosts and test targets are connected via USB (reliable).</li>
  <li>Apple Chow wrote about Octopus on <a href="http://eng.uber.com/rescued-by-octopus/">Uber Engineering</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Check Changes in a Commit and Invoke CI Tasks]]></title>
    <link href="http://euccas.github.io/blog/20160815/how-to-check-changes-in-a-commit-and-invoke-ci-tasks.html"/>
    <updated>2016-08-15T19:43:21-07:00</updated>
    <id>http://euccas.github.io/blog/20160815/how-to-check-changes-in-a-commit-and-invoke-ci-tasks</id>
    <content type="html"><![CDATA[<h1 id="problem-description">Problem Description</h1>

<p>Suppose one task in your Continuous Integration (CI) pipeline is triggered on every commit to the project repository. Some the files in the repository require passing the check of the CI task, while some other files do not require passing the check. What should the CI task do to decide if it is needed to perform the needed checking on the commit?</p>

<h1 id="design-the-ci-task">Design the CI task</h1>

<p>The CI task need have the ability to analyze the files included in the commit, and decide whether the commit requires passing a check, or not. We need tell the CI task which files require passing a check through configurations.</p>

<!--more-->

<h2 id="configuration">Configuration</h2>

<p>There are multiple ways to design the configurations, such as:</p>

<ol>
  <li>
    <p>Only list the files or paths requiring the check</p>
  </li>
  <li>
    <p>Only list the files or paths do not require the check</p>
  </li>
  <li>
    <p>List the files or paths requiring the check, and also list the subset files or paths that do not require the check</p>
  </li>
</ol>

<p>The 3rd way probably is the optimal one because it provides the flexibility for you to put a large scope path as the files need check, and then exclude a subset from the large scope path. For example:</p>

<p>```
check: my_project/dev/</p>

<p>skip: my_project/dev/test/</p>

<p>```</p>

<p>To apply the 3rd method, the configuration of the CI task will include two types: inclusion, and exclusion.</p>

<h2 id="analyze-files-in-the-commit">Analyze files in the commit</h2>

<p>The needed analysis process of the CI task is:</p>

<ul>
  <li>
    <p>If none of the files in the commit matches the inclusion in configuration, skip the check</p>
  </li>
  <li>
    <p>If all the files in the commit matching the inclusion in configuration also matching the exclusion in configuration, skip the check</p>
  </li>
  <li>
    <p>In other cases, the check for this commit is needed</p>
  </li>
</ul>

<p>The complexity of the given process is <em>O(n<sup>2</sup>)</em>.</p>

<p>A mistake that could happen in the analysis process is when you analyze the exclusion cases, you should do the analysis only on the files that match inclusion configuration, which is a subset of files in the commit.</p>

<h1 id="example-with-the-python">Example with the Python</h1>

<p>Here is the code written in Python for demonstrating the case discussed above.</p>

<ul>
  <li>
    <p><code>commit_files</code>: a list containing all the files in the commit</p>
  </li>
  <li>
    <p><code>config</code>: a dictionary containing inclusion and exclusion configurations</p>
  </li>
  <li>
    <p><code>config['include']</code>: a list containing all the files or paths need check</p>
  </li>
  <li>
    <p><code>config['exclude']</code>: a list containing the files or paths do not need check</p>
  </li>
</ul>

<p>```python</p>

<p>def analyze_commit_files(commit_files, config):</p>

<pre><code>need_check = False    


# commit need_check is False if:    

# - No files in this commit    

# - Config does not have any 'include' defined    

if commit_files is None or len(commit_files) == 0:

    return need_check

if not 'include' in config or config['include'] is None or len(config['include']) == 0:

    return need_check

# commit need_check is False if:    

# - All file in the commit matches the configured inclusion, OR    

# - All files in the commit that matches the inclusion, also match the configured exclusion    

# First check inclusion    

files_need_check = list()

for cf in commit_files:

    for check_file in config['include']:            

        if re.search(check_file, cf):                            

            files_need_check.append(cf)



if len(files_need_check) &gt; 0:

    # Check skip_path

    if not 'exclude' in config or config['exclude'] is None or len(config['exclude']) == 0:

        need_check = True

     else:

         for cf in files_need_check:

             for skip_file in config['exclude']:                         

                if not re.search(skip_file, cf):                       

                    need_check = True

                    break

return need_check
</code></pre>

<p>```</p>

]]></content>
  </entry>
  
</feed>
