<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Infrastructure | euccas.github.io]]></title>
  <link href="http://euccas.github.io/categories/infrastructure/atom.xml" rel="self"/>
  <link href="http://euccas.github.io/"/>
  <updated>2017-06-26T18:06:00-07:00</updated>
  <id>http://euccas.github.io/</id>
  <author>
    <name><![CDATA[euccas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A List of SoC Design and Verification Infrastructure Needs - Tools/Automation Flows (2013)]]></title>
    <link href="http://euccas.github.io/20170212/a-list-of-soc-design-and-verification-infrastructure-needs.html"/>
    <updated>2017-02-12T15:53:19-08:00</updated>
    <id>http://euccas.github.io/20170212/a-list-of-soc-design-and-verification-infrastructure-needs</id>
    <content type="html"><![CDATA[<p><em>This post was written in 2013, when I thought it was necessary to summarize infrastructure tools and flows needed in SoC design and verification, according to all my experience. Today when I checked on my old notes I found this one and would like to share it here. Later on I’ll update and expand this list according to my latest experience and knowledge in engineering tools and infrastructure for software and hardware development.</em></p>

<p>System-on-Chip design and verification process is a complicated one. Unlike the world of Web and Internet, the design and development of hardware products have higher risk and lower tolerance to any mistakes. SoC design and verification process requires collaborations from multiple teams and vendors. Lots of hard decisions to make. Lots of trade-offs to consider. Moreover, the nonrecurring-engineering (NRE) charge makes sufficient and solid verification a must with limited time and resource. Tools and automated flows are an essential part of any design house.</p>

<p>Here is a list of areas that need tools and flows for SoC software and hardware design and verification according to my experience.</p>

<!--more-->

<table>
<tr>
	<th>Usage Area of Tools/Flows</th>
	<th>Software</th>
	<th>Hardware</th>
	<th>Design Usage</th>
	<th>Verification Usage</th>
</tr>

<tr>
	<td>Test Generation</td>
	<td>x</td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Regression System</td>
	<td>x</td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Coverage Reporting</td>
	<td>x</td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Coding Style Check</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Code Review System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Code Quality Analysis</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Build System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

<tr>
	<td>Version Control</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

<tr>
	<td>Integration System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Spec System</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>RTL Generation</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>TestBench Generation</td>
	<td></td>
	<td>x</td>
	<td></td>
	<td>x</td>
</tr>

<tr>
	<td>Synthesis</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Netlist Quality Analysis</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Power Analysis and Optimization</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>ECO Flow</td>
	<td></td>
	<td>x</td>
	<td>x</td>
	<td></td>
</tr>

<tr>
	<td>Issue/Bug Tracking System</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

<tr>
	<td>Infrastructure: Linux/Windows machines, LSF</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
	<td>x</td>
</tr>

</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GTAC: The Uber Challenge of Cross-Application Testing]]></title>
    <link href="http://euccas.github.io/20160928/the-uber-challenge-of-cross-application-testinng.html"/>
    <updated>2016-09-28T23:17:30-07:00</updated>
    <id>http://euccas.github.io/20160928/the-uber-challenge-of-cross-application-testinng</id>
    <content type="html"><![CDATA[<p>Inspired by Matt Cutts’ TED talk: <a href="https://www.ted.com/talks/matt_cutts_try_something_new_for_30_days?language=en">Try something new for 30 days</a>, I’m starting a “30 Days of GTAC” project. Google’s Test Automation Conference <a href="https://developers.google.com/google-test-automation-conference/">GTAC</a> is an annual test automation conference which brings together engineers from industry and academia to discuss advances in test automation and related engineering tools. In my “30 Days of GTAC” project, I’ll review the topics presented on GTAC. My goal is having a better and deeper understanding in modern testing technologies, methodologies, strategies, and practices.</p>

<p>Get it started! Day#1 topic is:</p>

<p><strong>The Uber Challenge of Cross-Application/Cross-Device Testing</strong></p>

<!--more-->

<ul>
  <li>Presenter: Apple Chow (Uber), Bian Jiang (Uber)</li>
  <li><a href="https://www.youtube.com/watch?v=p6gsssppeT0&amp;list=PLSIUOFhnxEiCWGsN9t5A-XOhRbmz54IS1&amp;index=3">Video</a></li>
  <li><a href="https://docs.google.com/presentation/d/1vYXhkvgLKun72Ix91LQDDWZQdcY5VOBqKVvI1Y6riYo/pub">Slides</a></li>
</ul>

<p><strong>My takeaways</strong></p>

<ul>
  <li>The challenge: End-to-end tests require cross application communication (between rider app and driver app)</li>
  <li>Uber’s solution: Octopus
    <ul>
      <li>Octopus coordinates communication across different apps running on different devices</li>
      <li>This solution can be adopted for any tests that require coordination/communication across different apps or devices</li>
    </ul>
  </li>
  <li>What makes testing Uber’s mobile apps significantly different from testing Google Maps?</li>
  <li>Why (built) Octopus? Unified (iOS and Android). Extensible (Integrate with different UI testing frameworks). Parallelized. Signaling (enabling cross-app and cross-device testing).</li>
  <li>What does Octopus do? Prepare test targets. Run tests (handles signaling). Create test results reports. Pull test artifacts. Perform clean ups. All from simple command line.</li>
  <li>Signaling between driver test and rider test: Conducted with Test Host to improve the consistency. API readSignal (blocking), writeSignal (nonblocking). Test hosts and test targets are connected via USB (reliable).</li>
  <li>Apple Chow wrote about Octopus on <a href="http://eng.uber.com/rescued-by-octopus/">Uber Engineering</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[Case Study] Perform Checks on a Commit According to Its Included Files]]></title>
    <link href="http://euccas.github.io/20160815/case-study-check-on-a-commit-according-to-the-included-files.html"/>
    <updated>2016-08-15T19:43:21-07:00</updated>
    <id>http://euccas.github.io/20160815/case-study-check-on-a-commit-according-to-the-included-files</id>
    <content type="html"><![CDATA[<h1 id="problem-description">Problem Description</h1>

<p>Suppose one task in your Continuous Integration (CI) pipeline is triggered on every commit to the project repository. Some the files in the repository require passing the check of the CI task, while some other files do not require passing the check. What should the CI task do to decide if it is needed to perform the needed checking on the commit?</p>

<h1 id="design-the-ci-task">Design the CI task</h1>

<p>The CI task need have the ability to analyze the files included in the commit, and decide whether the commit requires passing a check, or not. We need tell the CI task which files require passing a check through configurations.</p>

<!--more-->

<h2 id="configuration">Configuration</h2>

<p>There are multiple ways to design the configurations, such as:</p>

<ol>
  <li>
    <p>Only list the files or paths requiring the check</p>
  </li>
  <li>
    <p>Only list the files or paths do not require the check</p>
  </li>
  <li>
    <p>List the files or paths requiring the check, and also list the subset files or paths that do not require the check</p>
  </li>
</ol>

<p>The 3rd way probably is the optimal one because it provides the flexibility for you to put a large scope path as the files need check, and then exclude a subset from the large scope path. For example:</p>

<p>```</p>

<p>check: my_project/dev/</p>

<p>skip: my_project/dev/test/</p>

<p>```</p>

<p>To apply the 3rd method, the configuration of the CI task will include two types: inclusion, and exclusion.</p>

<h2 id="analyze-files-in-the-commit">Analyze files in the commit</h2>

<p>The needed analysis process of the CI task is:</p>

<ul>
  <li>
    <p>If none of the files in the commit matches the inclusion in configuration, skip the check</p>
  </li>
  <li>
    <p>If all the files in the commit matching the inclusion in configuration also matching the exclusion in configuration, skip the check</p>
  </li>
  <li>
    <p>In other cases, the check for this commit is needed</p>
  </li>
</ul>

<p>The complexity of the given process is <em>O(n<sup>2</sup>)</em>.</p>

<p>A mistake that could happen in the analysis process is when you analyze the exclusion cases, you should do the analysis only on the files that match inclusion configuration, which is a subset of files in the commit.</p>

<h1 id="example-with-the-python">Example with the Python</h1>

<p>Here is the code written in Python for demonstrating the case discussed above.</p>

<ul>
  <li>
    <p><code>commit_files</code>: a list containing all the files in the commit</p>
  </li>
  <li>
    <p><code>config</code>: a dictionary containing inclusion and exclusion configurations</p>
  </li>
  <li>
    <p><code>config['include']</code>: a list containing all the files or paths need check</p>
  </li>
  <li>
    <p><code>config['exclude']</code>: a list containing the files or paths do not need check</p>
  </li>
</ul>

<p>```</p>

<p>def analyze_commit_files(commit_files, config):</p>

<pre><code>need_check = False    



# commit need_check is False if:    

# - No files in this commit    

# - Config does not have any 'include' defined    

if commit_files is None or len(commit_files) == 0:

    return need_check

if not 'include' in config or config['include'] is None or len(config['include']) == 0:

    return need_check

# commit need_check is False if:    

# - All file in the commit matches the configured inclusion, OR    

# - All files in the commit that matches the inclusion, also match the configured exclusion    

# First check inclusion    

files_need_check = list()

for cf in commit_files:

    for check_file in config['include']:            

        if re.search(check_file, cf):                            

            files_need_check.append(cf)



if len(files_need_check) &gt; 0:

    # Check skip_path

    if not 'exclude' in config or config['exclude'] is None or len(config['exclude']) == 0:

        need_check = True

     else:

         for cf in files_need_check:

             for skip_file in config['exclude']:                         

                if not re.search(skip_file, cf):                       

                    need_check = True

                    break

return need_check
</code></pre>

<p>```</p>

]]></content>
  </entry>
  
</feed>
